{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import TicTacToe\n",
    "from agent import AgentPPO, RandomAgent\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_game(agent: AgentPPO, opp: RandomAgent, env: TicTacToe):\n",
    "    # total_players = [agent, opp]\n",
    "    cur_player_index = np.random.randint(0, 2)\n",
    "    state = env.get_initial_state()\n",
    "\n",
    "    while True:\n",
    "        cur_player_index = cur_player_index % 2\n",
    "        if cur_player_index == 0:\n",
    "            availalbe_action = env.get_valid_moves(state)\n",
    "            action = agent.act(env.get_encoded_single_state(state), availalbe_action)\n",
    "            next_state = env.get_next_state(state, action)\n",
    "            reward, is_terminated = env.get_value_and_terminated(next_state, action)\n",
    "\n",
    "            if is_terminated:\n",
    "                return reward\n",
    "\n",
    "        else:\n",
    "            availalbe_action = env.get_valid_moves(state)\n",
    "            action = opp.act(state, availalbe_action)\n",
    "            next_state = env.get_next_state(state, action)\n",
    "            reward, is_terminated = env.get_value_and_terminated(next_state, action)\n",
    "            if is_terminated:\n",
    "                return -reward\n",
    "\n",
    "        state = env.reserve_state(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 100.pt perform 1207\n",
      "Agent 200.pt perform 1556\n",
      "Agent 300.pt perform 1552\n",
      "Agent 400.pt perform 1597\n",
      "Agent 500.pt perform 1630\n",
      "Agent 600.pt perform 1606\n",
      "Agent 700.pt perform 1612\n",
      "Agent 800.pt perform 1639\n",
      "Agent 900.pt perform 1622\n",
      "Agent 1000.pt perform 1677\n",
      "Agent 1100.pt perform 1815\n",
      "Agent 1200.pt perform 1819\n",
      "Agent 1300.pt perform 1793\n"
     ]
    }
   ],
   "source": [
    "game = TicTacToe()\n",
    "random_agent = RandomAgent()\n",
    "agent = AgentPPO(game.get_state_size(), game.action_size)\n",
    "folder_path = \"checkpoint\"\n",
    "all_files = [\n",
    "    f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))\n",
    "]\n",
    "\n",
    "all_files.sort(key=lambda x: int(\"\".join(filter(str.isdigit, x)) or 0))\n",
    "\n",
    "test_game = 2000\n",
    "\n",
    "\n",
    "def simulate_game(agent: AgentPPO, opp: RandomAgent, env: TicTacToe):\n",
    "    # total_players = [agent, opp]\n",
    "    cur_player_index = np.random.randint(0, 2)\n",
    "    state = env.get_initial_state()\n",
    "\n",
    "    while True:\n",
    "        cur_player_index = cur_player_index % 2\n",
    "        if cur_player_index == 0:\n",
    "            availalbe_action = env.get_valid_moves(state)\n",
    "            action = agent.act(env.get_encoded_single_state(state), availalbe_action)\n",
    "            next_state = env.get_next_state(state, action)\n",
    "            reward, is_terminated = env.get_value_and_terminated(next_state, action)\n",
    "\n",
    "            if is_terminated:\n",
    "                return reward\n",
    "\n",
    "        else:\n",
    "            availalbe_action = env.get_valid_moves(state)\n",
    "            action = opp.act(state, availalbe_action)\n",
    "            next_state = env.get_next_state(state, action)\n",
    "            reward, is_terminated = env.get_value_and_terminated(next_state, action)\n",
    "            if is_terminated:\n",
    "                return -reward\n",
    "\n",
    "        cur_player_index += 1\n",
    "\n",
    "        state = env.reserve_state(next_state)\n",
    "\n",
    "\n",
    "for f in all_files:\n",
    "    agent = AgentPPO(game.get_state_size(), game.action_size)\n",
    "    agent.load(f\"{folder_path}/{f}\")\n",
    "    result = 0\n",
    "    for i in range(test_game):\n",
    "        result += simulate_game(agent, random_agent, game)\n",
    "\n",
    "    print(f\"Agent {f} perform {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "action not valid\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "action not valid\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "action not valid\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "[[-1.  0.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  1.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  0.  1.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]]\n",
      "[[-1.  1. -1.]\n",
      " [ 1. -1. -1.]\n",
      " [-1.  1.  1.]]\n",
      "-1 won\n"
     ]
    }
   ],
   "source": [
    "agent = AgentPPO(game.get_state_size(), game.action_size)\n",
    "agent.load(f\"checkpoint/1100.pt\")\n",
    "\n",
    "\n",
    "player = -1\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        # row = int(input(f\"Row:\"))\n",
    "        # column = int(input(f\"Column:\"))\n",
    "\n",
    "        # action = row * game.row_count + column\n",
    "        action = int(input(f\"Action:\"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not valid\")\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        bot_state = game.reserve_state(state)\n",
    "        valids_move = game.get_valid_moves(bot_state)\n",
    "        action = agent.act(game.get_encoded_single_state(bot_state), valids_move)\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminal:\n",
    "        print(state)\n",
    "        if value == 1:\n",
    "            print(player, \"won\")\n",
    "        else:\n",
    "            print(\"draw\")\n",
    "        break\n",
    "\n",
    "    player = -player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded from checkpoints/1000.pth\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  0.  0.]]\n",
      "[[-1.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [-1.  1.  0.]]\n",
      "1 won\n"
     ]
    }
   ],
   "source": [
    "agent = AgentDQN(game.get_state_size(), game.action_size)\n",
    "agent.load(f\"checkpoints/1000.pth\")\n",
    "\n",
    "player = 1\n",
    "state = game.get_initial_state()\n",
    "\n",
    "while True:\n",
    "    print(state)\n",
    "\n",
    "    if player == 1:\n",
    "        valid_moves = game.get_valid_moves(state)\n",
    "        # row = int(input(f\"Row:\"))\n",
    "        # column = int(input(f\"Column:\"))\n",
    "\n",
    "        # action = row * game.row_count + column\n",
    "        action = int(input(f\"Action:\"))\n",
    "\n",
    "        if valid_moves[action] == 0:\n",
    "            print(\"action not valid\")\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        bot_state = game.reserve_state(state)\n",
    "        valids_move = game.get_valid_moves(bot_state)\n",
    "        action = agent.act(game.get_encoded_state(bot_state), valids_move)\n",
    "\n",
    "    state = game.get_next_state(state, action, player)\n",
    "\n",
    "    value, is_terminal = game.get_value_and_terminated(state, action)\n",
    "\n",
    "    if is_terminal:\n",
    "        print(state)\n",
    "        if value == 1:\n",
    "            print(player, \"won\")\n",
    "        else:\n",
    "            print(\"draw\")\n",
    "        break\n",
    "\n",
    "    player = -player"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlzh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
